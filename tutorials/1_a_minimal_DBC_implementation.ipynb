{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tutorial 1. A Minimal DBC (Diffusion Behavior Clone) Implementation**\n",
    "## 1 Introduction\n",
    "In this tutorial, we'll explore how to implement a minimal DBC (Diffusion Behavior Clone) with CleanDiffuser. \n",
    "DBC is an imitation learning algorithm that aims to replicate behaviors from the offline demonstration dataset. \n",
    "It uses the diffusion model to generate samples from the policy distribution $\\pi_\\theta(a|s)$. So the basic idea is just the same as the diffusion-based \n",
    "image generation model, but the difference is that DBC is conditioned on the state $s$ and generates actions $a$.\n",
    "\n",
    "Imitation learning requires a dataset of expert demonstrations. In this tutorial, we'll use the RelayKitchen environment, which consists of a 9 DoF position-controlled Franka robot interacting with a kitchen scene, including an openable microwave, four turnable oven burners, an oven light switch, a freely movable kettle, two hinged cabinets, and a sliding cabinet door. It also contains 566 human demonstrations of various tasks, such as opening the microwave, turning on the oven light, and moving the kettle. Agents are trained to imitate these demonstrations and finish as many tasks as possible within a limited time.\n",
    "\n",
    "Let's start by downloading the expert demonstrations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-18 14:24:41--  https://diffusion-policy.cs.columbia.edu/data/training/kitchen.zip\n",
      "Connecting to 127.0.0.1:7890... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 777744116 (742M) [application/zip]\n",
      "Saving to: ‘kitchen.zip’\n",
      "\n",
      "kitchen.zip           0%[                    ] 444.12K  15.6KB/s    eta 12h 35m^C\n",
      "Archive:  kitchen.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of kitchen.zip or\n",
      "        kitchen.zip.zip, and cannot find kitchen.zip.ZIP, period.\n"
     ]
    }
   ],
   "source": [
    "! mkdir ../dev\n",
    "! cd ../dev\n",
    "! wget https://diffusion-policy.cs.columbia.edu/data/training/kitchen.zip\n",
    "! unzip kitchen.zip\n",
    "! rm kitchen.zip\n",
    "! cd ../tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Setting up the Environment and Prepare the Dataset\n",
    "\n",
    "CleanDiffuser has already provided a simple interface to set up the environment and prepare the dataset. We'll have a gym-like environment to interact with, and a pytorch Dataset class by the following code. Note that `KitchenDataset` is a sequential dataset that returns the state-action trajectory segmentations in the demonstration dataset. The `horizon` parameter is the length of the trajectory segmentations, `pad_before` and `pad_after` are the padding length before and after the trajectory segmentations. Since we just consider single-step decision making here, we set `horizon=1`, `pad_before=0`, and `pad_after=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Finish loading data. Observation shape: torch.Size([1, 60]). Action shape torch.Size([1, 9]).\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from cleandiffuser.env import kitchen\n",
    "from cleandiffuser.dataset.kitchen_dataset import KitchenDataset\n",
    "\n",
    "\n",
    "env = gym.make('kitchen-all-v0')\n",
    "dataset = KitchenDataset(\"../dev/kitchen\", horizon=1, pad_before=0, pad_after=0)\n",
    "\n",
    "data = dataset[0]\n",
    "obs, act = data[\"obs\"][\"state\"], data[\"action\"]\n",
    "obs_dim, act_dim = obs.shape[-1], act.shape[-1]\n",
    "print(f'Finish loading data. Observation shape: {obs.shape}. Action shape {act.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Create the Diffusion Model\n",
    "\n",
    "We'll use the diffusion model to generate samples from the policy distribution $\\pi_\\theta(a|s)$. Following DBC, we use DDPM with `PearceMlp` as the neural network backbone and `PearceObsCondition` as the condition network. If you are familiar with the UNet architecture in the diffusion model, `PearceMlp` here just serves as the role of UNet in image generation. After creating the networks, we can create the diffusion model by integrating them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from cleandiffuser.diffusion import ContinuousDiffusionSDE\n",
    "from cleandiffuser.nn_condition import PearceObsCondition\n",
    "from cleandiffuser.nn_diffusion import PearceMlp\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "nn_diffusion = PearceMlp(act_dim=act_dim, To=1, emb_dim=128, hidden_dim=512, timestep_emb_type=\"untrainable_fourier\")\n",
    "\"\"\" nn.Module: xt (bs, act_dim) x t (bs, ) x condition (bs, To * emb_dim) -> eps_theta (bs, act_dim) \"\"\"\n",
    "nn_condition = PearceObsCondition(obs_dim=obs_dim, emb_dim=128, flatten=True, dropout=0.0)\n",
    "\"\"\" nn.Module: obs (bs, To, obs_dim) x t (bs, ) -> condition (bs, To * emb_dim) if `flatten` else (bs, To, emb_dim) \"\"\"\n",
    "\n",
    "actor = ContinuousDiffusionSDE(\n",
    "        nn_diffusion, nn_condition,\n",
    "        x_max=+1. * torch.ones(act_dim),\n",
    "        x_min=-1. * torch.ones(act_dim),\n",
    "        ema_rate=0.9999, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's further understand the used parameters here:\n",
    "\n",
    "**PearceMlp**\n",
    "- `act_dim`: (int) The dimension of the action space.\n",
    "- `To`: (int) Number of observations to condition on. `To=1` means the model conditions on only the current observation. `To>1` means the model conditions on the current and previous history observations.\n",
    "- `emb_dim`: (int) The embedding dimension of the neural network. Should match the `emb_dim` defined in the condition network.\n",
    "- `hidden_dim`: (int) The hidden dimension of the neural network.\n",
    "- `timestep_emb_type`: (str) The type of timestep embedding. Use `untrainable_fourier` or `fourier` for continuous time embeddings. Use `untrainable_positional` or `positional` for discrete time embeddings.\n",
    "\n",
    "**PearceObsCondition**\n",
    "- `obs_dim`: (int) The dimension of the observation space.\n",
    "- `emb_dim`: (int) The embedding dimension of the neural network. Should match the `emb_dim` defined in the backbone network.\n",
    "- `flatten`: (bool) Whether to flatten the input observation. Since `PearceMlp` requires a flattened input (bs, To * emb_dim), we set `flatten=True`.\n",
    "- `dropout`: (float) The *label* dropout rate. It should be larger than `0.0` if you want to use CFG (classifier-free guidance). Since we don't use CFG here (or you can regard it as a CFG always using guidance strength $w=1.0$), we set `dropout=0.0`.\n",
    "\n",
    "**ContinuousDiffusionSDE**\n",
    "- `nn_diffusion`: (DiffusionModel) The neural network backbone of the diffusion model.\n",
    "- `nn_condition`: (Optional[BaseNNCondition]) The condition network of the diffusion model. If `None`, the model is unconditioned. Here we set `nn_condition` to the condition network `PearceObsCondition`.\n",
    "- `x_max`: (Optional[torch.Tensor]) The maximum value of the generated tensor, i.e., action here. Since the action range is $[-1, 1]$, we set `x_max=1.0 * torch.ones(act_dim)`. Setting `x_max` can help constrain the generated action within the action range. If `None`, the model does not constrain the generated tensor.\n",
    "- `x_min`: (Optional[torch.Tensor]) The minimum value of the generated tensor, i.e., action here. Since the action range is $[-1, 1]$, we set `x_min=-1.0 * torch.ones(act_dim)`. Setting `x_min` can help constrain the generated action within the action range. If `None`, the model does not constrain the generated tensor.\n",
    "- `ema_rate`: (float) The exponential moving average rate. We set `ema_rate=0.9999` to stabilize the generation quality.\n",
    "- `device`: (Optional[torch.device]) Device.\n",
    "\n",
    "Before training, let's sample some actions from the untrained diffusion model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled actions: tensor([[-0.7280,  0.8175,  0.8965,  0.2809,  0.2374, -0.6952, -0.1831, -0.5356,\n",
      "         -0.7705],\n",
      "        [ 1.0000,  0.8923, -1.0000,  0.2930,  1.0000, -0.8390, -0.2525, -1.0000,\n",
      "          0.8997]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n_samples = 2\n",
    "sampled_acts, log = actor.sample(\n",
    "    prior=torch.zeros((n_samples, act_dim)), solver=\"ddpm\", n_samples=n_samples, sample_steps=5,\n",
    "    condition_cfg=obs.expand(2, 1, obs_dim).to(device), w_cfg=1.0)\n",
    "print(f'Sampled actions: {sampled_acts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampled actions are apparently meaningless. But we can see how to sample actions $a$ from the policy distribution $\\pi_\\theta(a|s)$ with `actor.sample()` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Training the Diffusion Model\n",
    "\n",
    "Training in CleanDiffuser is straightforward. We don't need to care about the loss details of each diffusion model. We just call `diffusion.update()` to update the model. Here we train the model to generate `act` conditioned on `obs` in the demonstration dataset. We train the model for 500k steps with a batch size of 256, and the learning rate is 3e-4 as default. (Actually, training for 100k steps can already get good performance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1000 | Loss: 0.2160250313580036\n",
      "Step: 2000 | Loss: 0.15241556303948164\n",
      "Step: 3000 | Loss: 0.1264905115365982\n",
      "Step: 4000 | Loss: 0.11397560276091098\n",
      "Step: 5000 | Loss: 0.10589095414429903\n",
      "Step: 6000 | Loss: 0.09958752532303333\n",
      "Step: 7000 | Loss: 0.09700235392153263\n",
      "Step: 8000 | Loss: 0.09425077591091395\n",
      "Step: 9000 | Loss: 0.09191515239700675\n",
      "Step: 10000 | Loss: 0.09019757077097892\n",
      "Step: 11000 | Loss: 0.08855000283569098\n",
      "Step: 12000 | Loss: 0.0871005589440465\n",
      "Step: 13000 | Loss: 0.08607586429268121\n",
      "Step: 14000 | Loss: 0.084725391946733\n",
      "Step: 15000 | Loss: 0.08386987456306814\n",
      "Step: 16000 | Loss: 0.08319094652310013\n",
      "Step: 17000 | Loss: 0.08236251272261143\n",
      "Step: 18000 | Loss: 0.08126343261823057\n",
      "Step: 19000 | Loss: 0.08104970243945718\n",
      "Step: 20000 | Loss: 0.07993688546493649\n",
      "Step: 21000 | Loss: 0.0791497498601675\n",
      "Step: 22000 | Loss: 0.07898339322209358\n",
      "Step: 23000 | Loss: 0.07859839364141226\n",
      "Step: 24000 | Loss: 0.07785627679899335\n",
      "Step: 25000 | Loss: 0.07722798414900899\n",
      "Step: 26000 | Loss: 0.07712671830877661\n",
      "Step: 27000 | Loss: 0.07595267363265157\n",
      "Step: 28000 | Loss: 0.07598521995916963\n",
      "Step: 29000 | Loss: 0.07603415954485536\n",
      "Step: 30000 | Loss: 0.07556103297322989\n",
      "Step: 31000 | Loss: 0.07509929334744811\n",
      "Step: 32000 | Loss: 0.07494243403896689\n",
      "Step: 33000 | Loss: 0.07420605822652579\n",
      "Step: 34000 | Loss: 0.07373909367620946\n",
      "Step: 35000 | Loss: 0.07386860276013613\n",
      "Step: 36000 | Loss: 0.07331661119684577\n",
      "Step: 37000 | Loss: 0.07250570062175393\n",
      "Step: 38000 | Loss: 0.07247793119773269\n",
      "Step: 39000 | Loss: 0.07275446892902256\n",
      "Step: 40000 | Loss: 0.07164915032684803\n",
      "Step: 41000 | Loss: 0.07222409934550524\n",
      "Step: 42000 | Loss: 0.07209985368326306\n",
      "Step: 43000 | Loss: 0.07143349394202232\n",
      "Step: 44000 | Loss: 0.07132473284751177\n",
      "Step: 45000 | Loss: 0.07118003182113171\n",
      "Step: 46000 | Loss: 0.07033960992097854\n",
      "Step: 47000 | Loss: 0.07034205178543926\n",
      "Step: 48000 | Loss: 0.07065184637531638\n",
      "Step: 49000 | Loss: 0.07058021531626582\n",
      "Step: 50000 | Loss: 0.0705924951210618\n",
      "Step: 51000 | Loss: 0.06943247049674392\n",
      "Step: 52000 | Loss: 0.06991035692766309\n",
      "Step: 53000 | Loss: 0.06957371652126312\n",
      "Step: 54000 | Loss: 0.06947466361522675\n",
      "Step: 55000 | Loss: 0.06955103180930018\n",
      "Step: 56000 | Loss: 0.0689132980182767\n",
      "Step: 57000 | Loss: 0.06892949125543237\n",
      "Step: 58000 | Loss: 0.06876958731934428\n",
      "Step: 59000 | Loss: 0.06854025940224528\n",
      "Step: 60000 | Loss: 0.06887613965198397\n",
      "Step: 61000 | Loss: 0.06805082493647933\n",
      "Step: 62000 | Loss: 0.06837588367238641\n",
      "Step: 63000 | Loss: 0.06861647731438279\n",
      "Step: 64000 | Loss: 0.06724176014959812\n",
      "Step: 65000 | Loss: 0.06761237827688456\n",
      "Step: 66000 | Loss: 0.06782027902826666\n",
      "Step: 67000 | Loss: 0.0677151473723352\n",
      "Step: 68000 | Loss: 0.0673314037322998\n",
      "Step: 69000 | Loss: 0.06720721184834838\n",
      "Step: 70000 | Loss: 0.06693711161240935\n",
      "Step: 71000 | Loss: 0.06669912295788527\n",
      "Step: 72000 | Loss: 0.0664730627052486\n",
      "Step: 73000 | Loss: 0.06613006756454706\n",
      "Step: 74000 | Loss: 0.06686702305451035\n",
      "Step: 75000 | Loss: 0.06709975321218371\n",
      "Step: 76000 | Loss: 0.06661893314123153\n",
      "Step: 77000 | Loss: 0.06616506803408265\n",
      "Step: 78000 | Loss: 0.06608726009353995\n",
      "Step: 79000 | Loss: 0.06647050011903048\n",
      "Step: 80000 | Loss: 0.06626751687377691\n",
      "Step: 81000 | Loss: 0.06564123618602753\n",
      "Step: 82000 | Loss: 0.06586574607342481\n",
      "Step: 83000 | Loss: 0.06594797867909073\n",
      "Step: 84000 | Loss: 0.06569456953555346\n",
      "Step: 85000 | Loss: 0.06534033601358533\n",
      "Step: 86000 | Loss: 0.0653462852537632\n",
      "Step: 87000 | Loss: 0.06548884522914887\n",
      "Step: 88000 | Loss: 0.06504344093054533\n",
      "Step: 89000 | Loss: 0.0654814526513219\n",
      "Step: 90000 | Loss: 0.0645981214120984\n",
      "Step: 91000 | Loss: 0.06455560133606196\n",
      "Step: 92000 | Loss: 0.0649596332423389\n",
      "Step: 93000 | Loss: 0.06473293931409717\n",
      "Step: 94000 | Loss: 0.06472336238250137\n",
      "Step: 95000 | Loss: 0.06434632018208504\n",
      "Step: 96000 | Loss: 0.06438292192667723\n",
      "Step: 97000 | Loss: 0.06424609461799263\n",
      "Step: 98000 | Loss: 0.0647088621556759\n",
      "Step: 99000 | Loss: 0.06447825799509883\n",
      "Step: 100000 | Loss: 0.06429413859173655\n",
      "Step: 101000 | Loss: 0.06376937480270863\n",
      "Step: 102000 | Loss: 0.06352446126565338\n",
      "Step: 103000 | Loss: 0.06359048258140683\n",
      "Step: 104000 | Loss: 0.06356614242494106\n",
      "Step: 105000 | Loss: 0.0634737057313323\n",
      "Step: 106000 | Loss: 0.06373521842807531\n",
      "Step: 107000 | Loss: 0.06373887556605042\n",
      "Step: 108000 | Loss: 0.06318441704101861\n",
      "Step: 109000 | Loss: 0.06324307667277754\n",
      "Step: 110000 | Loss: 0.06345585979521275\n",
      "Step: 111000 | Loss: 0.06281585761904716\n",
      "Step: 112000 | Loss: 0.06282723979279399\n",
      "Step: 113000 | Loss: 0.06294251321256161\n",
      "Step: 114000 | Loss: 0.06310558606684208\n",
      "Step: 115000 | Loss: 0.06279515378549695\n",
      "Step: 116000 | Loss: 0.062371428269892934\n",
      "Step: 117000 | Loss: 0.0626524120606482\n",
      "Step: 118000 | Loss: 0.06255157863721252\n",
      "Step: 119000 | Loss: 0.0629503646939993\n",
      "Step: 120000 | Loss: 0.06281687760353089\n",
      "Step: 121000 | Loss: 0.06239458965882659\n",
      "Step: 122000 | Loss: 0.06251221303269267\n",
      "Step: 123000 | Loss: 0.06246390078216791\n",
      "Step: 124000 | Loss: 0.06221739713475108\n",
      "Step: 125000 | Loss: 0.06225818470865488\n",
      "Step: 126000 | Loss: 0.06286855122819543\n",
      "Step: 127000 | Loss: 0.06194560841098428\n",
      "Step: 128000 | Loss: 0.061816006496548656\n",
      "Step: 129000 | Loss: 0.06251159756630659\n",
      "Step: 130000 | Loss: 0.06232043220475316\n",
      "Step: 131000 | Loss: 0.06193465177342296\n",
      "Step: 132000 | Loss: 0.06203968723863363\n",
      "Step: 133000 | Loss: 0.0615258506834507\n",
      "Step: 134000 | Loss: 0.06157431556656957\n",
      "Step: 135000 | Loss: 0.06192619833350182\n",
      "Step: 136000 | Loss: 0.06150273585692048\n",
      "Step: 137000 | Loss: 0.06117797951027751\n",
      "Step: 138000 | Loss: 0.061384687449783086\n",
      "Step: 139000 | Loss: 0.062154343135654926\n",
      "Step: 140000 | Loss: 0.061417606003582474\n",
      "Step: 141000 | Loss: 0.06105026618763804\n",
      "Step: 142000 | Loss: 0.061482946619391445\n",
      "Step: 143000 | Loss: 0.06092012749239802\n",
      "Step: 144000 | Loss: 0.06136851571127772\n",
      "Step: 145000 | Loss: 0.06109053466655314\n",
      "Step: 146000 | Loss: 0.061073102299124\n",
      "Step: 147000 | Loss: 0.06122829228267074\n",
      "Step: 148000 | Loss: 0.061511551417410375\n",
      "Step: 149000 | Loss: 0.06048460159823298\n",
      "Step: 150000 | Loss: 0.060854991547763346\n",
      "Step: 151000 | Loss: 0.06072946485504508\n",
      "Step: 152000 | Loss: 0.05984535300731659\n",
      "Step: 153000 | Loss: 0.060823967043310403\n",
      "Step: 154000 | Loss: 0.06088056118786335\n",
      "Step: 155000 | Loss: 0.06128506987169385\n",
      "Step: 156000 | Loss: 0.060497668463736776\n",
      "Step: 157000 | Loss: 0.060091903872787955\n",
      "Step: 158000 | Loss: 0.06076018599793315\n",
      "Step: 159000 | Loss: 0.06028923950344324\n",
      "Step: 160000 | Loss: 0.05994805593043566\n",
      "Step: 161000 | Loss: 0.06005441894382239\n",
      "Step: 162000 | Loss: 0.05981320896744728\n",
      "Step: 163000 | Loss: 0.06000435063615441\n",
      "Step: 164000 | Loss: 0.06014185433089733\n",
      "Step: 165000 | Loss: 0.06012857564911246\n",
      "Step: 166000 | Loss: 0.06009024680405855\n",
      "Step: 167000 | Loss: 0.05991410651057959\n",
      "Step: 168000 | Loss: 0.05992799149826169\n",
      "Step: 169000 | Loss: 0.05950705361366272\n",
      "Step: 170000 | Loss: 0.059496093548834325\n",
      "Step: 171000 | Loss: 0.06013932854309678\n",
      "Step: 172000 | Loss: 0.05984319913946092\n",
      "Step: 173000 | Loss: 0.06003721434995532\n",
      "Step: 174000 | Loss: 0.05912153496593237\n",
      "Step: 175000 | Loss: 0.05964262999966741\n",
      "Step: 176000 | Loss: 0.059592640299350026\n",
      "Step: 177000 | Loss: 0.05948758068308234\n",
      "Step: 178000 | Loss: 0.05923598643764853\n",
      "Step: 179000 | Loss: 0.059398322392255065\n",
      "Step: 180000 | Loss: 0.059266441214829685\n",
      "Step: 181000 | Loss: 0.05930842514336109\n",
      "Step: 182000 | Loss: 0.05902356288023293\n",
      "Step: 183000 | Loss: 0.059152993243187665\n",
      "Step: 184000 | Loss: 0.058897762175649404\n",
      "Step: 185000 | Loss: 0.058897567860782145\n",
      "Step: 186000 | Loss: 0.058720922581851485\n",
      "Step: 187000 | Loss: 0.058865208093076944\n",
      "Step: 188000 | Loss: 0.05927216249704361\n",
      "Step: 189000 | Loss: 0.05813838784769178\n",
      "Step: 190000 | Loss: 0.058947934966534374\n",
      "Step: 191000 | Loss: 0.05891249280795455\n",
      "Step: 192000 | Loss: 0.058921502452343705\n",
      "Step: 193000 | Loss: 0.058927067171782255\n",
      "Step: 194000 | Loss: 0.05862176351249218\n",
      "Step: 195000 | Loss: 0.058681317497044805\n",
      "Step: 196000 | Loss: 0.05874054258689285\n",
      "Step: 197000 | Loss: 0.058946941137313844\n",
      "Step: 198000 | Loss: 0.05850568840280175\n",
      "Step: 199000 | Loss: 0.059189541157335046\n",
      "Step: 200000 | Loss: 0.058353258684277536\n",
      "Step: 201000 | Loss: 0.05796050721779466\n",
      "Step: 202000 | Loss: 0.05873495520465076\n",
      "Step: 203000 | Loss: 0.05765899953059852\n",
      "Step: 204000 | Loss: 0.05783083152770996\n",
      "Step: 205000 | Loss: 0.05806206279993057\n",
      "Step: 206000 | Loss: 0.05832003602385521\n",
      "Step: 207000 | Loss: 0.05827410919964313\n",
      "Step: 208000 | Loss: 0.05833125639334321\n",
      "Step: 209000 | Loss: 0.05767008551210165\n",
      "Step: 210000 | Loss: 0.05802588290348649\n",
      "Step: 211000 | Loss: 0.057644324351102116\n",
      "Step: 212000 | Loss: 0.057698663813993335\n",
      "Step: 213000 | Loss: 0.05742324963957071\n",
      "Step: 214000 | Loss: 0.057344369482249025\n",
      "Step: 215000 | Loss: 0.05803247318230569\n",
      "Step: 216000 | Loss: 0.0581266982704401\n",
      "Step: 217000 | Loss: 0.05744782405346632\n",
      "Step: 218000 | Loss: 0.05710295622423291\n",
      "Step: 219000 | Loss: 0.057345495641231536\n",
      "Step: 220000 | Loss: 0.057667982012033464\n",
      "Step: 221000 | Loss: 0.056876986313611266\n",
      "Step: 222000 | Loss: 0.058154808027669785\n",
      "Step: 223000 | Loss: 0.057504061758518216\n",
      "Step: 224000 | Loss: 0.05800577257946134\n",
      "Step: 225000 | Loss: 0.057987077716737986\n",
      "Step: 226000 | Loss: 0.057433246020227674\n",
      "Step: 227000 | Loss: 0.05747236402332783\n",
      "Step: 228000 | Loss: 0.05753750964440405\n",
      "Step: 229000 | Loss: 0.057577978648245334\n",
      "Step: 230000 | Loss: 0.05710325564444065\n",
      "Step: 231000 | Loss: 0.05755939505249262\n",
      "Step: 232000 | Loss: 0.05772108007222414\n",
      "Step: 233000 | Loss: 0.056619461815804246\n",
      "Step: 234000 | Loss: 0.05726982157304883\n",
      "Step: 235000 | Loss: 0.05700529811158776\n",
      "Step: 236000 | Loss: 0.05684199996478856\n",
      "Step: 237000 | Loss: 0.05727738416567445\n",
      "Step: 238000 | Loss: 0.05709733702242374\n",
      "Step: 239000 | Loss: 0.05655705128982663\n",
      "Step: 240000 | Loss: 0.05683828106895089\n",
      "Step: 241000 | Loss: 0.056049116406589744\n",
      "Step: 242000 | Loss: 0.0570970669221133\n",
      "Step: 243000 | Loss: 0.05668861031532288\n",
      "Step: 244000 | Loss: 0.055978595927357676\n",
      "Step: 245000 | Loss: 0.05681869811564684\n",
      "Step: 246000 | Loss: 0.05673307237401605\n",
      "Step: 247000 | Loss: 0.05604568126052618\n",
      "Step: 248000 | Loss: 0.056291036654263736\n",
      "Step: 249000 | Loss: 0.056421693831682204\n",
      "Step: 250000 | Loss: 0.056450748017057774\n",
      "Step: 251000 | Loss: 0.05631202894821763\n",
      "Step: 252000 | Loss: 0.055924274565652014\n",
      "Step: 253000 | Loss: 0.056340636998414996\n",
      "Step: 254000 | Loss: 0.0565651125498116\n",
      "Step: 255000 | Loss: 0.05680784353613853\n",
      "Step: 256000 | Loss: 0.05593846236355603\n",
      "Step: 257000 | Loss: 0.056421135671436785\n",
      "Step: 258000 | Loss: 0.055532258875668046\n",
      "Step: 259000 | Loss: 0.056084515620023014\n",
      "Step: 260000 | Loss: 0.05643437612429261\n",
      "Step: 261000 | Loss: 0.05563565750792623\n",
      "Step: 262000 | Loss: 0.056172678211703894\n",
      "Step: 263000 | Loss: 0.055741961911320685\n",
      "Step: 264000 | Loss: 0.05580047714151442\n",
      "Step: 265000 | Loss: 0.05593647416122258\n",
      "Step: 266000 | Loss: 0.055629064360633494\n",
      "Step: 267000 | Loss: 0.05601716059073806\n",
      "Step: 268000 | Loss: 0.055886709913611415\n",
      "Step: 269000 | Loss: 0.05600947234034538\n",
      "Step: 270000 | Loss: 0.05603492453321814\n",
      "Step: 271000 | Loss: 0.055556535188108686\n",
      "Step: 272000 | Loss: 0.05534858414530754\n",
      "Step: 273000 | Loss: 0.05594988319277763\n",
      "Step: 274000 | Loss: 0.055425981203094124\n",
      "Step: 275000 | Loss: 0.05571382662467658\n",
      "Step: 276000 | Loss: 0.056395430879667405\n",
      "Step: 277000 | Loss: 0.054884673792868856\n",
      "Step: 278000 | Loss: 0.05551854250021279\n",
      "Step: 279000 | Loss: 0.05620767926052213\n",
      "Step: 280000 | Loss: 0.05514271306432784\n",
      "Step: 281000 | Loss: 0.05532086138054729\n",
      "Step: 282000 | Loss: 0.055372485442087054\n",
      "Step: 283000 | Loss: 0.05518556710705161\n",
      "Step: 284000 | Loss: 0.055696331810206175\n",
      "Step: 285000 | Loss: 0.05533191743306816\n",
      "Step: 286000 | Loss: 0.05531900958158076\n",
      "Step: 287000 | Loss: 0.05470252480357885\n",
      "Step: 288000 | Loss: 0.055017400551587346\n",
      "Step: 289000 | Loss: 0.05502486020699143\n",
      "Step: 290000 | Loss: 0.05554182932339609\n",
      "Step: 291000 | Loss: 0.055355244690552356\n",
      "Step: 292000 | Loss: 0.05520359133556485\n",
      "Step: 293000 | Loss: 0.054900881808251145\n",
      "Step: 294000 | Loss: 0.055711642947047946\n",
      "Step: 295000 | Loss: 0.054863095993176104\n",
      "Step: 296000 | Loss: 0.05449687331356108\n",
      "Step: 297000 | Loss: 0.0551912746578455\n",
      "Step: 298000 | Loss: 0.05431291076168418\n",
      "Step: 299000 | Loss: 0.054617016702890396\n",
      "Step: 300000 | Loss: 0.054862890999764206\n",
      "Step: 301000 | Loss: 0.05503346044011414\n",
      "Step: 302000 | Loss: 0.05453845461085439\n",
      "Step: 303000 | Loss: 0.05468574097380042\n",
      "Step: 304000 | Loss: 0.05454375046491623\n",
      "Step: 305000 | Loss: 0.05510342165641487\n",
      "Step: 306000 | Loss: 0.054720445133745674\n",
      "Step: 307000 | Loss: 0.05455572123639286\n",
      "Step: 308000 | Loss: 0.05453307125903666\n",
      "Step: 309000 | Loss: 0.054273427307605746\n",
      "Step: 310000 | Loss: 0.054341307448223235\n",
      "Step: 311000 | Loss: 0.054474590258672836\n",
      "Step: 312000 | Loss: 0.05503153382614255\n",
      "Step: 313000 | Loss: 0.054584524001926184\n",
      "Step: 314000 | Loss: 0.054641111297532914\n",
      "Step: 315000 | Loss: 0.05459493797644973\n",
      "Step: 316000 | Loss: 0.054570898074656725\n",
      "Step: 317000 | Loss: 0.05447907761111855\n",
      "Step: 318000 | Loss: 0.05436065973713994\n",
      "Step: 319000 | Loss: 0.05395081766694784\n",
      "Step: 320000 | Loss: 0.05389702737517655\n",
      "Step: 321000 | Loss: 0.05394091949798167\n",
      "Step: 322000 | Loss: 0.05431803358346224\n",
      "Step: 323000 | Loss: 0.05416653128899634\n",
      "Step: 324000 | Loss: 0.054673824520781636\n",
      "Step: 325000 | Loss: 0.054401354901492595\n",
      "Step: 326000 | Loss: 0.053937599347904326\n",
      "Step: 327000 | Loss: 0.05387531217373907\n",
      "Step: 328000 | Loss: 0.05403444817662239\n",
      "Step: 329000 | Loss: 0.05437927970662713\n",
      "Step: 330000 | Loss: 0.054255388597026465\n",
      "Step: 331000 | Loss: 0.053452377835288646\n",
      "Step: 332000 | Loss: 0.05385996857099235\n",
      "Step: 333000 | Loss: 0.05415640535950661\n",
      "Step: 334000 | Loss: 0.053984544986858965\n",
      "Step: 335000 | Loss: 0.053743329463526605\n",
      "Step: 336000 | Loss: 0.0537741320040077\n",
      "Step: 337000 | Loss: 0.05402727934345603\n",
      "Step: 338000 | Loss: 0.05385285725072026\n",
      "Step: 339000 | Loss: 0.05435160641744733\n",
      "Step: 340000 | Loss: 0.05362216262333095\n",
      "Step: 341000 | Loss: 0.053844723157584665\n",
      "Step: 342000 | Loss: 0.053449291829019786\n",
      "Step: 343000 | Loss: 0.05317881434969604\n",
      "Step: 344000 | Loss: 0.05363727767020464\n",
      "Step: 345000 | Loss: 0.053849476424977186\n",
      "Step: 346000 | Loss: 0.05375339099019766\n",
      "Step: 347000 | Loss: 0.05329477621428669\n",
      "Step: 348000 | Loss: 0.05333323789015412\n",
      "Step: 349000 | Loss: 0.05345925087109208\n",
      "Step: 350000 | Loss: 0.05397017639130354\n",
      "Step: 351000 | Loss: 0.05377102067321539\n",
      "Step: 352000 | Loss: 0.05370370805077255\n",
      "Step: 353000 | Loss: 0.05357892862521112\n",
      "Step: 354000 | Loss: 0.053080624490976336\n",
      "Step: 355000 | Loss: 0.05363021298870444\n",
      "Step: 356000 | Loss: 0.0533651763331145\n",
      "Step: 357000 | Loss: 0.05323277195170522\n",
      "Step: 358000 | Loss: 0.05327299405261874\n",
      "Step: 359000 | Loss: 0.053231991732493045\n",
      "Step: 360000 | Loss: 0.05335336830466986\n",
      "Step: 361000 | Loss: 0.05297300501726568\n",
      "Step: 362000 | Loss: 0.0532667903508991\n",
      "Step: 363000 | Loss: 0.05326848085597157\n",
      "Step: 364000 | Loss: 0.053000185016542675\n",
      "Step: 365000 | Loss: 0.05310715824365616\n",
      "Step: 366000 | Loss: 0.05266462785750627\n",
      "Step: 367000 | Loss: 0.053077605625614525\n",
      "Step: 368000 | Loss: 0.053357966311275956\n",
      "Step: 369000 | Loss: 0.05293879134021699\n",
      "Step: 370000 | Loss: 0.05312313219346106\n",
      "Step: 371000 | Loss: 0.05237800571322441\n",
      "Step: 372000 | Loss: 0.05280092894844711\n",
      "Step: 373000 | Loss: 0.053219311447814104\n",
      "Step: 374000 | Loss: 0.05318468093313277\n",
      "Step: 375000 | Loss: 0.0528968196362257\n",
      "Step: 376000 | Loss: 0.05281765421293676\n",
      "Step: 377000 | Loss: 0.05264251251518726\n",
      "Step: 378000 | Loss: 0.05314802996255458\n",
      "Step: 379000 | Loss: 0.052440758498385545\n",
      "Step: 380000 | Loss: 0.052568573156371715\n",
      "Step: 381000 | Loss: 0.05228842491470277\n",
      "Step: 382000 | Loss: 0.052430470863357184\n",
      "Step: 383000 | Loss: 0.05249934758618474\n",
      "Step: 384000 | Loss: 0.05271201927401126\n",
      "Step: 385000 | Loss: 0.05273685963824391\n",
      "Step: 386000 | Loss: 0.052017678543925285\n",
      "Step: 387000 | Loss: 0.05222470204345882\n",
      "Step: 388000 | Loss: 0.05246403690427542\n",
      "Step: 389000 | Loss: 0.05268581945635378\n",
      "Step: 390000 | Loss: 0.052345318092033265\n",
      "Step: 391000 | Loss: 0.052827957844361666\n",
      "Step: 392000 | Loss: 0.05248973253555596\n",
      "Step: 393000 | Loss: 0.052728857360780236\n",
      "Step: 394000 | Loss: 0.05259449976310134\n",
      "Step: 395000 | Loss: 0.05231188918277621\n",
      "Step: 396000 | Loss: 0.05228551226295531\n",
      "Step: 397000 | Loss: 0.05207647544145584\n",
      "Step: 398000 | Loss: 0.05243193346261978\n",
      "Step: 399000 | Loss: 0.052003407299518585\n",
      "Step: 400000 | Loss: 0.05228031286783517\n",
      "Step: 401000 | Loss: 0.051948459714651105\n",
      "Step: 402000 | Loss: 0.05174766177870333\n",
      "Step: 403000 | Loss: 0.05213766236975789\n",
      "Step: 404000 | Loss: 0.05241251893155277\n",
      "Step: 405000 | Loss: 0.05218326441571117\n",
      "Step: 406000 | Loss: 0.051686629921197894\n",
      "Step: 407000 | Loss: 0.051997277876362206\n",
      "Step: 408000 | Loss: 0.05241380352899432\n",
      "Step: 409000 | Loss: 0.052360464161261916\n",
      "Step: 410000 | Loss: 0.0522222304251045\n",
      "Step: 411000 | Loss: 0.052244502641260626\n",
      "Step: 412000 | Loss: 0.05199134915322065\n",
      "Step: 413000 | Loss: 0.05241474039293826\n",
      "Step: 414000 | Loss: 0.052113773841410874\n",
      "Step: 415000 | Loss: 0.05213185163401067\n",
      "Step: 416000 | Loss: 0.0520788201186806\n",
      "Step: 417000 | Loss: 0.05158701894246042\n",
      "Step: 418000 | Loss: 0.05182962732389569\n",
      "Step: 419000 | Loss: 0.05140193923190236\n",
      "Step: 420000 | Loss: 0.0516846444029361\n",
      "Step: 421000 | Loss: 0.05148887400701642\n",
      "Step: 422000 | Loss: 0.05096606818959117\n",
      "Step: 423000 | Loss: 0.051880306141451\n",
      "Step: 424000 | Loss: 0.05165392629802227\n",
      "Step: 425000 | Loss: 0.05116298002190888\n",
      "Step: 426000 | Loss: 0.05105274995416403\n",
      "Step: 427000 | Loss: 0.05183654473721981\n",
      "Step: 428000 | Loss: 0.05130209787003696\n",
      "Step: 429000 | Loss: 0.05140273870155215\n",
      "Step: 430000 | Loss: 0.05167820041626692\n",
      "Step: 431000 | Loss: 0.05132988814450801\n",
      "Step: 432000 | Loss: 0.051578644387423996\n",
      "Step: 433000 | Loss: 0.05134265113249421\n",
      "Step: 434000 | Loss: 0.05141560391150415\n",
      "Step: 435000 | Loss: 0.05109460713714361\n",
      "Step: 436000 | Loss: 0.05138463331572712\n",
      "Step: 437000 | Loss: 0.05138238492980599\n",
      "Step: 438000 | Loss: 0.051875569919124245\n",
      "Step: 439000 | Loss: 0.051354510083794595\n",
      "Step: 440000 | Loss: 0.05123988867178559\n",
      "Step: 441000 | Loss: 0.05156637083180249\n",
      "Step: 442000 | Loss: 0.050895763073116544\n",
      "Step: 443000 | Loss: 0.05130387020669878\n",
      "Step: 444000 | Loss: 0.05120822907797992\n",
      "Step: 445000 | Loss: 0.0512467626594007\n",
      "Step: 446000 | Loss: 0.0512665664665401\n",
      "Step: 447000 | Loss: 0.051478225899860265\n",
      "Step: 448000 | Loss: 0.0511216341201216\n",
      "Step: 449000 | Loss: 0.05108251316100359\n",
      "Step: 450000 | Loss: 0.050981712168082595\n",
      "Step: 451000 | Loss: 0.05149021700024605\n",
      "Step: 452000 | Loss: 0.05138392038084567\n",
      "Step: 453000 | Loss: 0.05065952611155808\n",
      "Step: 454000 | Loss: 0.05177966328524053\n",
      "Step: 455000 | Loss: 0.05079624034650624\n",
      "Step: 456000 | Loss: 0.05086560483276844\n",
      "Step: 457000 | Loss: 0.05121440825797617\n",
      "Step: 458000 | Loss: 0.051011325335130094\n",
      "Step: 459000 | Loss: 0.05131669636815786\n",
      "Step: 460000 | Loss: 0.05106595182605088\n",
      "Step: 461000 | Loss: 0.050419441357254985\n",
      "Step: 462000 | Loss: 0.05134338239207864\n",
      "Step: 463000 | Loss: 0.051104812705889346\n",
      "Step: 464000 | Loss: 0.0509702313747257\n",
      "Step: 465000 | Loss: 0.05063942705467343\n",
      "Step: 466000 | Loss: 0.05046155418083072\n",
      "Step: 467000 | Loss: 0.050829291658475995\n",
      "Step: 468000 | Loss: 0.05077002863585949\n",
      "Step: 469000 | Loss: 0.05087517426535487\n",
      "Step: 470000 | Loss: 0.05080303804203868\n",
      "Step: 471000 | Loss: 0.05009889246895909\n",
      "Step: 472000 | Loss: 0.05073900318145752\n",
      "Step: 473000 | Loss: 0.05073316429555416\n",
      "Step: 474000 | Loss: 0.05117635527253151\n",
      "Step: 475000 | Loss: 0.05059913343936205\n",
      "Step: 476000 | Loss: 0.050307175459340214\n",
      "Step: 477000 | Loss: 0.05064644808322191\n",
      "Step: 478000 | Loss: 0.05056090967915952\n",
      "Step: 479000 | Loss: 0.050095698168501256\n",
      "Step: 480000 | Loss: 0.05058607793599367\n",
      "Step: 481000 | Loss: 0.05085241493023932\n",
      "Step: 482000 | Loss: 0.050669597858563065\n",
      "Step: 483000 | Loss: 0.05089097972214222\n",
      "Step: 484000 | Loss: 0.050422831235453484\n",
      "Step: 485000 | Loss: 0.05011126227118075\n",
      "Step: 486000 | Loss: 0.05064349700883031\n",
      "Step: 487000 | Loss: 0.05028612667322159\n",
      "Step: 488000 | Loss: 0.0503044973500073\n",
      "Step: 489000 | Loss: 0.05036516793817282\n",
      "Step: 490000 | Loss: 0.050503367917612195\n",
      "Step: 491000 | Loss: 0.05065146681666374\n",
      "Step: 492000 | Loss: 0.05037648094445467\n",
      "Step: 493000 | Loss: 0.05080189193785191\n",
      "Step: 494000 | Loss: 0.05036012815311551\n",
      "Step: 495000 | Loss: 0.050164688445627686\n",
      "Step: 496000 | Loss: 0.04967771801911294\n",
      "Step: 497000 | Loss: 0.05020569384470582\n",
      "Step: 498000 | Loss: 0.05055632347799838\n",
      "Step: 499000 | Loss: 0.04991798867098987\n",
      "Step: 500000 | Loss: 0.050500145798549056\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from cleandiffuser.utils import loop_dataloader\n",
    "\n",
    "\n",
    "savepath = \"./tutorials/results/1_a_minimal_DBC_implementation/\"\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "\n",
    "n_gradient_steps = 0\n",
    "avg_loss = 0.\n",
    "actor.train()\n",
    "for batch in loop_dataloader(dataloader):\n",
    "    \n",
    "    obs, act = batch[\"obs\"][\"state\"][:, 0].to(device), batch[\"action\"][:, 0].to(device)\n",
    "    \n",
    "    avg_loss += actor.update(x0=act, condition=obs)[\"loss\"]\n",
    "    \n",
    "    n_gradient_steps += 1\n",
    "    \n",
    "    if n_gradient_steps % 1000 == 0:\n",
    "        print(f'Step: {n_gradient_steps} | Loss: {avg_loss / 1000}')\n",
    "        avg_loss = 0.\n",
    "    \n",
    "    if n_gradient_steps % 100_000 == 0:\n",
    "        actor.save(savepath + \"diffusion.pt\")\n",
    "    \n",
    "    if n_gradient_steps == 500_000:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Evaluation\n",
    "\n",
    "Let's see how our DBC performs in the RelayKitchen environment! We parallelly interact with 50 environments and use 3 random seeds to evaluate the performance. The evaluation metric is the success rate to finish `n` tasks. We use DDPM with 5 sampling steps (compared to 50 sampling steps used in DBC official implementation) to generate actions. The results show that we can achieve a success rate of 76.67% to finish 4 tasks, compared to 68% in the DBC paper report!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading configurations for Franka\n",
      "\u001b[40m\u001b[97mInitializing Franka sim\u001b[0m\n",
      "Task kettle completed!\n",
      "Task bottom burner completed!\n",
      "Task top burner completed!\n",
      "Task hinge cabinet completed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "solver = \"ddpm\"\n",
    "sampling_step = 5\n",
    "num_episodes = 3\n",
    "num_envs = 50\n",
    "savepath = \"./tutorials/results/1_a_minimal_DBC_implementation/\"\n",
    "\n",
    "actor.load(savepath + \"diffusion.pt\")\n",
    "actor.eval()\n",
    "\n",
    "# Parallelize evaluation\n",
    "# env_eval = gym.vector.make('kitchen-all-v0', num_envs=num_envs)\n",
    "\n",
    "# Get normalizers\n",
    "normalizers = dataset.get_normalizer()\n",
    "state_normalizer = normalizers[\"obs\"][\"state\"]\n",
    "action_normalizer = normalizers[\"action\"]\n",
    "\n",
    "# all_rews = []\n",
    "# for n in range(num_episodes):\n",
    "    \n",
    "#     obs, done, ep_rews, ep_len = env_eval.reset(), False, 0., 0\n",
    "#     prior = torch.zeros((num_envs, act_dim), device=device)\n",
    "#     while not np.all(done):\n",
    "        \n",
    "#         obs = state_normalizer.normalize(obs)\n",
    "        \n",
    "#         act, log = actor.sample(\n",
    "#             prior, solver=solver, n_samples=num_envs, sample_steps=sampling_step,\n",
    "#             sample_step_schedule=\"quad_continuous\",\n",
    "#             w_cfg=1.0, condition_cfg=torch.tensor(obs, device=device, dtype=torch.float32))\n",
    "#         act = act.cpu().numpy()\n",
    "        \n",
    "#         act = action_normalizer.unnormalize(act)\n",
    "        \n",
    "#         obs, rew, _done, info = env_eval.step(act)\n",
    "#         ep_rews += rew * (1 - done)\n",
    "#         done = np.logical_or(done, _done)\n",
    "#         ep_len += 1\n",
    "        \n",
    "#         print(f'[({n + 1}/{num_episodes}), t={ep_len}] Episode reward: {ep_rews}')\n",
    "\n",
    "#     all_rews.append(ep_rews)\n",
    "\n",
    "# all_rews = np.array(all_rews)\n",
    "# task_sr = np.zeros((7, ))\n",
    "# for i in range(7):\n",
    "#     task_sr[i] = (all_rews > i).sum() / (num_episodes * num_envs)\n",
    "    \n",
    "# print(f'Evaluated {int(num_episodes * num_envs)} episodes.')\n",
    "# print(f'Task success rate: {np.round(task_sr * 100., 2)}')\n",
    "\n",
    "\n",
    "import imageio\n",
    "\n",
    "env = gym.make('kitchen-all-v0')\n",
    "obs = env.reset()\n",
    "frames = []\n",
    "done = False\n",
    "prior = torch.zeros((1, act_dim), device=device)\n",
    "while not done:  # 50 steps\n",
    "    obs = state_normalizer.normalize(obs)\n",
    "    # Expand obs to [batch_size, 1, obs_dim]\n",
    "    obs_tensor = torch.tensor(obs, device=device, dtype=torch.float32).unsqueeze(0).unsqueeze(1) \n",
    "\n",
    "    act, log = actor.sample(\n",
    "        prior, solver=solver, n_samples=1, sample_steps=sampling_step,\n",
    "        sample_step_schedule=\"quad_continuous\",\n",
    "        w_cfg=1.0, condition_cfg=obs_tensor)\n",
    "    act = act.cpu().numpy()\n",
    "    act = action_normalizer.unnormalize(act)\n",
    "    act = act.squeeze()  # Ensure shape is (act_dim,)\n",
    "    frame = env.render(mode='rgb_array')  # Get image frame\n",
    "    frames.append(frame)\n",
    "   # Random action, replace with your policy\n",
    "    obs, reward, done, info = env.step(act)\n",
    "\n",
    "\n",
    "# Save as GIF\n",
    "imageio.mimsave('kitchen_animation.gif', frames, fps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
